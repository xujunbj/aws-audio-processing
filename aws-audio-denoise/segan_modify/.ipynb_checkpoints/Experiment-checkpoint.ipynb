{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sagemaker\n",
    "import tensorflow as tf\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"sagemaker\"\n"
     ]
    }
   ],
   "source": [
    "# !pygmentize 'source/core/step_three_recognize_process/tools/train/\n",
    "\n",
    "#single gpu training\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "# Can be local_gpu, local, or ml.p3.2xlarge, ml.p3.8xlarge etc.\n",
    "instance_type='ml.p3.2xlarge'\n",
    "#bucket=\"<your-s3-bucket-name>\"\n",
    "bucket=\"uwo-bkt-xj\"\n",
    "prefix=\"audio-denoise\"\n",
    "\n",
    "#inputs=\"s3://sagemaker-us-east-1-002224604296/denoise/tfrecords/\"\n",
    "input_path='s3://{}/{}/train/'.format(bucket, prefix)\n",
    "hyperparameters = {'servable_model_dir': '/opt/ml/model', \n",
    "                   'epoch': 1, \n",
    "                   'task_type': 'train', \n",
    "                   'sagemaker': 'true'\n",
    "                  }\n",
    "# requirements.txt are not allowed in script mode (BYOS). https://stackoverflow.com/q/53530867/3252127\n",
    "# Hyperparameters are specified in the model_config.py file, we need to extract them out to use SageMaker automl features.\n",
    "segan_estimator = TensorFlow(entry_point='source/main_train_deploy.py',\n",
    "                             source_dir='.',\n",
    "                             model_dir='/opt/ml/model',\n",
    "                             role=role,\n",
    "                             output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                             framework_version='1.15.2',\n",
    "                             hyperparameters=hyperparameters, #set weights_path if you are finetune a pretrained model\n",
    "                             py_version='py2',\n",
    "                             train_instance_type=instance_type,\n",
    "                             train_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-25 06:09:28 Starting - Starting the training job...\n",
      "2020-06-25 06:09:30 Starting - Launching requested ML instances.........\n",
      "2020-06-25 06:11:05 Starting - Preparing the instances for training......\n",
      "2020-06-25 06:12:06 Downloading - Downloading input data............\n",
      "2020-06-25 06:14:25 Training - Training image download completed. Training in progress..\u001b[34mWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-06-25 06:14:30,096 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-06-25 06:14:30,752 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"module_dir\": \"s3://uwo-bkt-xj/tensorflow-training-2020-06-25-06-09-27-366/source/sourcedir.tar.gz\", \n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    }, \n",
      "    \"resource_config\": {\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ], \n",
      "        \"network_interface_name\": \"eth0\", \n",
      "        \"current_host\": \"algo-1\"\n",
      "    }, \n",
      "    \"num_cpus\": 8, \n",
      "    \"log_level\": 20, \n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\", \n",
      "    \"input_config_dir\": \"/opt/ml/input/config\", \n",
      "    \"additional_framework_parameters\": {}, \n",
      "    \"output_data_dir\": \"/opt/ml/output/data\", \n",
      "    \"output_dir\": \"/opt/ml/output\", \n",
      "    \"model_dir\": \"/opt/ml/model\", \n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ], \n",
      "    \"master_hostname\": \"algo-1\", \n",
      "    \"hyperparameters\": {\n",
      "        \"sagemaker\": \"true\", \n",
      "        \"epoch\": 1, \n",
      "        \"task_type\": \"train\", \n",
      "        \"servable_model_dir\": \"/opt/ml/model\", \n",
      "        \"model_dir\": \"/opt/ml/model\"\n",
      "    }, \n",
      "    \"network_interface_name\": \"eth0\", \n",
      "    \"num_gpus\": 1, \n",
      "    \"input_dir\": \"/opt/ml/input\", \n",
      "    \"user_entry_point\": \"source/main_train_deploy.py\", \n",
      "    \"job_name\": \"tensorflow-training-2020-06-25-06-09-27-366\", \n",
      "    \"current_host\": \"algo-1\", \n",
      "    \"is_master\": true, \n",
      "    \"module_name\": \"source/main_train_deploy\", \n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\", \n",
      "            \"RecordWrapperType\": \"None\", \n",
      "            \"S3DistributionType\": \"FullyReplicated\"\n",
      "        }\n",
      "    }, \n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=source/main_train_deploy.py\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=source/main_train_deploy\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epoch\":1,\"model_dir\":\"/opt/ml/model\",\"sagemaker\":\"true\",\"servable_model_dir\":\"/opt/ml/model\",\"task_type\":\"train\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-06-25-06-09-27-366\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://uwo-bkt-xj/tensorflow-training-2020-06-25-06-09-27-366/source/sourcedir.tar.gz\",\"module_name\":\"source/main_train_deploy\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"source/main_train_deploy.py\"}\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_HP_SERVABLE_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epoch\",\"1\",\"--model_dir\",\"/opt/ml/model\",\"--sagemaker\",\"true\",\"--servable_model_dir\",\"/opt/ml/model\",\"--task_type\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_HP_TASK_TYPE=train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCH=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://uwo-bkt-xj/tensorflow-training-2020-06-25-06-09-27-366/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epoch\":1,\"model_dir\":\"/opt/ml/model\",\"sagemaker\":\"true\",\"servable_model_dir\":\"/opt/ml/model\",\"task_type\":\"train\"}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_SAGEMAKER=true\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python2.7:/usr/lib/python2.7/plat-x86_64-linux-gnu:/usr/lib/python2.7/lib-tk:/usr/lib/python2.7/lib-old:/usr/lib/python2.7/lib-dynload:/usr/local/lib/python2.7/dist-packages:/usr/lib/python2.7/dist-packages\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python source/main_train_deploy.py --epoch 1 --model_dir /opt/ml/model --sagemaker true --servable_model_dir /opt/ml/model --task_type train\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From source/main_train_deploy.py:308: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\u001b[0m\n",
      "\u001b[34mParsed arguments:  {'helpfull': <absl.app.HelpfullFlag object at 0x7f1a567da350>, 'deconv_type': <absl.flags._flag.Flag object at 0x7f1a567e5a90>, 'd_label_smooth': <absl.flags._flag.Flag object at 0x7f1a567e5650>, 'z_depth': <absl.flags._flag.Flag object at 0x7f1a567e5850>, 'help': <absl.app.HelpFlag object at 0x7f1a567da2d0>, 'servable_model_dir': <absl.flags._flag.Flag object at 0x7f1a567da210>, 'showprefixforinfo': <absl.flags._flag.BooleanFlag object at 0x7f1a88bb41d0>, 'stderrthreshold': <absl.logging._StderrthresholdFlag object at 0x7f1a88bb4150>, 'op_conversion_fallback_to_while_loop': <absl.flags._flag.BooleanFlag object at 0x7f1acebc8390>, 'seed': <absl.flags._flag.Flag object at 0x7f1a5fb59890>, 'test_randomize_ordering_seed': <absl.flags._flag.Flag object at 0x7f1a6c1de110>, 'dataset_dir': <absl.flags._flag.Flag object at 0x7f1a567da190>, 'init_noise_std': <absl.flags._flag.Flag object at 0x7f1a567e56d0>, 'synthesis_path': <absl.flags._flag.Flag object at 0x7f1a567e5d90>, 'e2e_dataset': <absl.flags._flag.Flag object at 0x7f1a567e5e50>, 'save_freq': <absl.flags._flag.Flag object at 0x7f1a567e5250>, 'task_type': <absl.flags._flag.Flag object at 0x7f1a567da110>, 'alsologtostderr': <absl.flags._flag.BooleanFlag object at 0x7f1a88baeed0>, 'logtostderr': <absl.flags._flag.BooleanFlag object at 0x7f1a88baedd0>, 'g_type': <absl.flags._flag.Flag object at 0x7f1a567e5b10>, 'l1_remove_epoch': <absl.flags._flag.Flag object at 0x7f1a567e53d0>, 'epoch': <absl.flags._flag.Flag object at 0x7f1a567e5150>, 'bias_D_conv': <absl.flags._flag.BooleanFlag object at 0x7f1a567e5490>, 'log_dir': <absl.flags._flag.Flag object at 0x7f1a88baef90>, 'save_path': <absl.flags._flag.Flag object at 0x7f1a567e58d0>, 'test_wav': <absl.flags._flag.Flag object at 0x7f1a567e5fd0>, 'test_tmpdir': <absl.flags._flag.Flag object at 0x7f1a6c1dc490>, 'sagemaker': <absl.flags._flag.Flag object at 0x7f1a567da290>, 'preemph': <absl.flags._flag.Flag object at 0x7f1a567e5d10>, 'run_with_profiling': <absl.flags._flag.BooleanFlag object at 0x7f1a88ba5910>, '?': <absl.app.HelpFlag object at 0x7f1a567da2d0>, 'run_with_pdb': <absl.flags._flag.BooleanFlag object at 0x7f1a88ba5d90>, 'g_learning_rate': <absl.flags._flag.Flag object at 0x7f1a567e5b90>, 'use_cprofile_for_profiling': <absl.flags._flag.BooleanFlag object at 0x7f1a88bb4690>, 'helpshort': <absl.app.HelpshortFlag object at 0x7f1a567da310>, 'xml_output_file': <absl.flags._flag.Flag object at 0x7f1a6c1f4690>, 'z_dim': <absl.flags._flag.Flag object at 0x7f1a567e57d0>, 'batch_size': <absl.flags._flag.Flag object at 0x7f1a567e51d0>, 'bias_downconv': <absl.flags._flag.BooleanFlag object at 0x7f1a567e5450>, 'denoise_epoch': <absl.flags._flag.Flag object at 0x7f1a567e5350>, 'canvas_size': <absl.flags._flag.Flag object at 0x7f1a567e52d0>, 'noise_decay': <absl.flags._flag.Flag object at 0x7f1a567e55d0>, 'g_nl': <absl.flags._flag.Flag object at 0x7f1a567e5990>, 'test_random_seed': <absl.flags._flag.Flag object at 0x7f1a6c216050>, 'beta_1': <absl.flags._flag.Flag object at 0x7f1a567e5c90>, 'profile_file': <absl.flags._flag.Flag object at 0x7f1a88bb4650>, 'd_learning_rate': <absl.flags._flag.Flag object at 0x7f1a567e5c10>, 'verbosity': <absl.logging._VerbosityFlag object at 0x7f1a88baefd0>, 'pdb_post_mortem': <absl.flags._flag.BooleanFlag object at 0x7f1a88ba5290>, 'only_check_args': <absl.flags._flag.BooleanFlag object at 0x7f1a88bb46d0>, 'test_srcdir': <absl.flags._flag.Flag object at 0x7f1a6c1dc310>, 'bias_deconv': <absl.flags._flag.BooleanFlag object at 0x7f1a567e5410>, 'weights': <absl.flags._flag.Flag object at 0x7f1a567da090>, 'v': <absl.logging._VerbosityFlag object at 0x7f1a88baefd0>, 'model': <absl.flags._flag.Flag object at 0x7f1a567e5a10>, 'helpxml': <absl.app.HelpXMLFlag object at 0x7f1a567da390>, 'denoise_lbound': <absl.flags._flag.Flag object at 0x7f1a567e5550>, 'save_clean_path': <absl.flags._flag.Flag object at 0x7f1a567e5f10>, 'init_l1_weight': <absl.flags._flag.Flag object at 0x7f1a567e5750>}\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From source/main_train_deploy.py:281: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0625 06:14:34.774667 139753197680448 module_wrapper.py:139] From source/main_train_deploy.py:281: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1a567da4d0>, '_model_dir': 'segan_results', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': gpu_options {\n",
      "  allow_growth: true\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mallow_soft_placement: true\u001b[0m\n",
      "\u001b[34m, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_session_creation_timeout_secs': 7200, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_experimental_max_worker_delay_secs': None, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\u001b[0m\n",
      "\u001b[34mI0625 06:14:34.775393 139753197680448 estimator.py:212] Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1a567da4d0>, '_model_dir': 'segan_results', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': gpu_options {\n",
      "  allow_growth: true\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mallow_soft_placement: true\u001b[0m\n",
      "\u001b[34m, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_session_creation_timeout_secs': 7200, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_experimental_max_worker_delay_secs': None, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\u001b[0m\n",
      "\u001b[34m!!!!!!!!!!!!!!!!!epoch is 1\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/training_util.py:236: initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34mW0625 06:14:34.788594 139753197680448 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/training_util.py:236: initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From source/main_train_deploy.py:104: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\u001b[0m\n",
      "\u001b[34mW0625 06:14:34.798010 139753197680448 deprecation.py:323] From source/main_train_deploy.py:104: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\u001b[0m\n",
      "\u001b[34mW0625 06:14:34.802249 139753197680448 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\u001b[0m\n",
      "\u001b[34mW0625 06:14:34.803035 139753197680448 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/input.py:112: count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPrefer Dataset.range instead.\u001b[0m\n",
      "\u001b[34mW0625 06:14:34.805623 139753197680448 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/input.py:112: count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPrefer Dataset.range instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/variables.py:2522: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPrefer Dataset.range instead.\u001b[0m\n",
      "\u001b[34mW0625 06:14:34.805778 139753197680448 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/variables.py:2522: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPrefer Dataset.range instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/input.py:198: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mW0625 06:14:34.808240 139753197680448 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/input.py:198: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mW0625 06:14:34.809216 139753197680448 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/source/data_loader.py:31: __init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\u001b[0m\n",
      "\u001b[34mW0625 06:14:34.812731 139753197680448 deprecation.py:323] From /opt/ml/code/source/data_loader.py:31: __init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/source/data_loader.py:33: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0625 06:14:34.813827 139753197680448 module_wrapper.py:139] From /opt/ml/code/source/data_loader.py:33: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/ml/code/source/data_loader.py:36: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0625 06:14:34.814008 139753197680448 module_wrapper.py:139] From /opt/ml/code/source/data_loader.py:36: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[0m\n",
      "\u001b[34mTensor(\"concat:0\", shape=(16384,), dtype=float32, device=/device:CPU:0)\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From source/main_train_deploy.py:130: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\u001b[0m\n",
      "\u001b[34mW0625 06:14:34.850183 139753197680448 deprecation.py:323] From source/main_train_deploy.py:130: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\u001b[0m\n",
      "\u001b[34mTensor(\"wav_and_noisy:0\", shape=(150, 16384), dtype=float32, device=/device:CPU:0)\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From source/main_train_deploy.py:134: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse eager execution and: \u001b[0m\n",
      "\u001b[34m`tf.data.TFRecordDataset(path)`\u001b[0m\n",
      "\u001b[34mW0625 06:14:34.859817 139753197680448 deprecation.py:323] From source/main_train_deploy.py:134: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse eager execution and: \u001b[0m\n",
      "\u001b[34m`tf.data.TFRecordDataset(path)`\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"source/main_train_deploy.py\", line 308, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 299, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 250, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"source/main_train_deploy.py\", line 293, in main\n",
      "    Segan.train(input_fn=lambda: input_fn(\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1188, in _train_model_default\n",
      "    input_fn, ModeKeys.TRAIN))\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1025, in _get_features_and_labels_from_input_fn\n",
      "    self._call_input_fn(input_fn, mode))\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1116, in _call_input_fn\n",
      "    return input_fn(**kwargs)\n",
      "  File \"source/main_train_deploy.py\", line 294, in <lambda>\n",
      "    dataset_dir=FLAGS.dataset_dir, canvas_size=FLAGS.canvas_size, preemph=FLAGS.preemph, num_epochs=1, batch_size=FLAGS.batch_size))\n",
      "  File \"source/main_train_deploy.py\", line 134, in input_fn\n",
      "    for record in tf.python_io.tf_record_iterator(dataset_dir):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/lib/io/tf_record.py\", line 174, in tf_record_iterator\n",
      "    compat.as_bytes(path), 0, compat.as_bytes(compression_type), status)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/errors_impl.py\", line 556, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\u001b[0m\n",
      "\u001b[34mtensorflow.python.framework.errors_impl.NotFoundError: /opt/ml/input/data/training/train/segan.tfrecords; No such file or directory\u001b[0m\n",
      "\u001b[34m2020-06-25 06:14:35,196 sagemaker-containers ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/usr/bin/python source/main_train_deploy.py --epoch 1 --model_dir /opt/ml/model --sagemaker true --servable_model_dir /opt/ml/model --task_type train\"\u001b[0m\n",
      "\n",
      "2020-06-25 06:14:43 Uploading - Uploading generated training model\n",
      "2020-06-25 06:14:43 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job tensorflow-training-2020-06-25-06-09-27-366: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/bin/python source/main_train_deploy.py --epoch 1 --model_dir /opt/ml/model --sagemaker true --servable_model_dir /opt/ml/model --task_type train\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-05ee7c9c431f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegan_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/sagemaker/tensorflow/estimator.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config, run_tensorboard_locally)\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/sagemaker/tensorflow/estimator.pyc\u001b[0m in \u001b[0;36mfit_super\u001b[0;34m()\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_tensorboard_locally\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/sagemaker/estimator.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/sagemaker/estimator.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/sagemaker/session.pyc\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3045\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/sagemaker/session.pyc\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2636\u001b[0m                 ),\n\u001b[1;32m   2637\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2638\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2639\u001b[0m             )\n\u001b[1;32m   2640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job tensorflow-training-2020-06-25-06-09-27-366: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/bin/python source/main_train_deploy.py --epoch 1 --model_dir /opt/ml/model --sagemaker true --servable_model_dir /opt/ml/model --task_type train\""
     ]
    }
   ],
   "source": [
    "result = segan_estimator.fit(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=segan_estimator.deploy(initial_instance_count=1, \n",
    "                                 instance_type='ml.g4dn.xlarge', \n",
    "                                 endpoint_type='tensorflow-serving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def de_emph(y, coeff=0.95):\n",
    "    if coeff <= 0:\n",
    "        return y\n",
    "    x = np.zeros(y.shape[0], dtype=np.float32)\n",
    "    x[0] = y[0]\n",
    "    for n in range(1, y.shape[0], 1):\n",
    "        x[n] = coeff * x[n - 1] + y[n]\n",
    "    return x\n",
    "\n",
    "def pre_emph_np(x, coeff=0.95):\n",
    "    x0 = np.reshape(x[0], [1,])\n",
    "    diff = x[1:] - coeff * x[:-1]\n",
    "#     concat = tf.concat(0, [x0, diff])\n",
    "    concat = np.concatenate([x0, diff], 0)\n",
    "    return concat\n",
    "\n",
    "def pre_emph_test_np(coeff, wav):\n",
    "    x_preemph = pre_emph_np(wav, coeff)\n",
    "    return x_preemph\n",
    "    \n",
    "def clean_serving(x, canvas_size, preemph, predictor=None):\n",
    "    \"\"\" clean a utterance x\n",
    "        x: numpy array containing the normalized noisy waveform\n",
    "    \"\"\"\n",
    "    c_res = None\n",
    "    print('start timer')\n",
    "    Time1 = time.time()\n",
    "    for beg_i in range(0, x.shape[0], canvas_size):\n",
    "        if x.shape[0] - beg_i  < canvas_size:\n",
    "            length = x.shape[0] - beg_i\n",
    "            pad = canvas_size - length\n",
    "        else:\n",
    "            length = canvas_size\n",
    "            pad = 0\n",
    "        x_ = np.zeros((1, canvas_size))\n",
    "        print(x_[0].shape)\n",
    "        if pad > 0:\n",
    "            x_ = np.concatenate((x[beg_i:beg_i + length], np.zeros(pad)))\n",
    "        else:\n",
    "            x_ = x[beg_i:beg_i + length]\n",
    "        print('Cleaning chunk {} -> {}'.format(beg_i, beg_i + length))\n",
    "        canvas_w = None\n",
    "        # fdict = {self.gtruth_noisy[0]:x_}\n",
    "        # canvas_w = self.sess.run(self.Gs[0],\n",
    "        #                         feed_dict=fdict)[0]\n",
    "        test_example = {'wav_and_noisy': x_.tolist()}\n",
    "        if predictor == None:\n",
    "            canvas_w = x_\n",
    "        else:\n",
    "            canvas_w = predictor.predict(test_example)\n",
    "        canvas_w = np.reshape(np.array(canvas_w['predictions']),canvas_size)\n",
    "        print('canvas w shape: ', canvas_w.shape)\n",
    "        if pad > 0:\n",
    "            print('Removing padding of {} samples'.format(pad))\n",
    "            # get rid of last padded samples\n",
    "            canvas_w = canvas_w[:-pad]\n",
    "        if c_res is None:\n",
    "            c_res = canvas_w\n",
    "        else:\n",
    "            c_res = np.concatenate((c_res, canvas_w))\n",
    "    # deemphasize\n",
    "    c_res = de_emph(c_res, preemph)\n",
    "    print('finish {}'.format(time.time()-Time1))\n",
    "    return c_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_wav = \"../../record_noise/record_noise_28_clip_0.wav\"\n",
    "!wget https://uwo-bkt-xj.s3-us-west-2.amazonaws.com/audio-denoise/test_sample/record_noise_22_clip_0.wav ./test_sample/\n",
    "test_wav = \"./test_sample/record_noise_28_clip_0.wav\"\n",
    "preemph = 0.95\n",
    "canvas_size = 2**14\n",
    "\n",
    "fm, wav_data = wavfile.read(test_wav)\n",
    "wavname = test_wav.split('/')[-1]\n",
    "wave = (2./65535.) * (wav_data.astype(np.float32) - 32767) + 1.\n",
    "\n",
    "x_pholder_np = pre_emph_test_np(preemph, wave)\n",
    "\n",
    "c_wave = clean_serving(x=x_pholder_np, canvas_size=canvas_size, preemph=preemph, predictor=predictor)\n",
    "\n",
    "wavfile.write(os.path.join('../../clean', wavname), 16e3, c_wave)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
